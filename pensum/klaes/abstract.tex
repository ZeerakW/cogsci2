\documentclass[11pt,a4paper]{article}

\usepackage{graphicx}
\usepackage[utf8]{inputenc}

\begin{document}


\title{Cognitive Science 2 synopsis abstract}
\author{Klaes Rasmussen (twb822)}
\date{}
\maketitle

I will implement a machine learning system that is trained on drawn or cartoonish hand gestures for gesture recognition. It is tested on counterpart basic and iconic human hand gestures to see wether it is possible to create a link between the two. It is limited to just two gestures for now, making a ``Peace'' sign or giving a ``thumbs up''. This is relevant for any kind of human gesturing where we wish to be able to preprogram the gesture, using a drawn representation of the gesture as training. Further development may be done for more gestures, and moving gestures. We may also be able to train an A.I. interface in conveying emotions to users, using or ``acting'' out gestures.

\vspace{1.5pc}

Note: I am working with Zeerak Butt on the coding of this as it is mutually beneficial. We can test our model on the others training set. We will also be comparing the direction of the information flow and see which works best and how to improve on our results when working together. Some data is best retrieved from humans and some best from drawings. Also computer mediated communication can be improved as a direct extension of our combined work.

\bibliography{..reference}
\bibliographystyle{apalike}
\nocite{*}

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
